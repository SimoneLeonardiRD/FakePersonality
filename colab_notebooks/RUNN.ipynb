{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RUNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rBZVS9GpnDu"
      },
      "source": [
        "# Relaiable Users Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxjqFRFmGVg"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezCdYws_mUAW"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mf0xZ1szvb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CYOt4SUT7I"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJuRGQ7Mubmj"
      },
      "source": [
        "from numpy.random import seed\n",
        "from numpy.random import randint\n",
        "import torch\n",
        "import numpy as np\n",
        "# seed random number generator\n",
        "seed(1)\n",
        "values = randint(0, 2, 10)\n",
        "print(values)\n",
        "labels = torch.from_numpy(values)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqtuupvowSxs"
      },
      "source": [
        "pRoot = \"drive/MyDrive/Colab Notebooks/\"\n",
        "pData = pRoot + \"dataset/\"\n",
        "pModels = pRoot + \"models/\"\n",
        "pTweet = pData + \"tweet/\"\n",
        "users_id = []\n",
        "fin = open(pData + \"users_fake_news.txt\", \"r\")\n",
        "for line in fin.readlines():\n",
        "    users_id.append(line.rstrip(\"\\n\"))\n",
        "users_id = users_id[1:11]\n",
        "#print(users_id)\n",
        "print(len(users_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbIfwbuJUz7"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
        "    'distilbert-base-multilingual-cased',\n",
        "    do_lower_case=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ZwcerzcrFr"
      },
      "source": [
        "def preprocess_sentences(input_ids, attention_masks, sentences):\n",
        "  for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_len,\n",
        "        # pad_to_max_length = True,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geCE30CVSdMb"
      },
      "source": [
        "def load_model(modelname):\n",
        "  loaded_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    pModels+modelname, output_hidden_states = True)\n",
        "  return loaded_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MCO6sXoFkOs"
      },
      "source": [
        "Read the first 100 tweets of each user and transform them into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwdheGgZFjvG"
      },
      "source": [
        "import pandas as pd\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "import gc\n",
        "\n",
        "# traits_big5 = ['O','C','E','A','N']\n",
        "# traits_bhv = ['SD', 'ST', 'HE', 'AC', 'PO', 'SE', 'CO', 'TR', 'BE', 'UN']\n",
        "'''\n",
        "trait = \"UN\"\n",
        "max_len = 256 # the closest power of two exceeding max len found\n",
        "model = load_model(\"distil_\"+trait)\n",
        "\n",
        "for user in users_id:   \n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  df = pd.read_csv(pTweet + str(user) + \".csv\")\n",
        "  # print(df.head())\n",
        "  df = df[:50]\n",
        "  df['text']= df['text'].astype('str')\n",
        "  sentences  = df.text.values\n",
        "  input_ids, attention_masks = preprocess_sentences(\n",
        "      input_ids, attention_masks, sentences)\n",
        "  input_ids = input_ids.to(device)\n",
        "  attention_masks = attention_masks.to(device)\n",
        "  pt_output = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "  token_embeddings = torch.stack(pt_output.hidden_states, dim=0)\n",
        "  # print(token_embeddings.size())\n",
        "  last_layer = token_embeddings[-1]\n",
        "  last_layer = last_layer.permute(1,0,2) \n",
        "  # print(last_layer[0].size())\n",
        "  result = last_layer[0].cpu().detach().numpy()\n",
        "  res = np.asarray(result)\n",
        "  np.savetxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\", res, delimiter=\",\", fmt='%5.5f')\n",
        "  del input_ids\n",
        "  del attention_masks\n",
        "  del pt_output\n",
        "  del df\n",
        "  del last_layer\n",
        "  del result\n",
        "  del res\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "print(\"done\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWtDsHkqHh5d"
      },
      "source": [
        "Prepare data into input tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_k3bQzp5Ofk"
      },
      "source": [
        "traits_big5 = ['O','C','E','A','N']\n",
        "traits_bhv = ['SD', 'ST', 'HE', 'AC', 'PO', 'SE', 'CO', 'TR', 'BE', 'UN']\n",
        "flag_tot = 0\n",
        "for user in users_id[:5]:\n",
        "  flag = 0\n",
        "  for trait in traits_big5:\n",
        "    torch_in = torch.from_numpy(\n",
        "        np.loadtxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\",\n",
        "        delimiter=\",\"))\n",
        "    if flag == 0 :\n",
        "      b5 = torch_in\n",
        "      flag = 1\n",
        "    else:\n",
        "      b5 = torch.cat((b5, torch_in), dim=1)\n",
        "  #print(b5.size())\n",
        "  flag = 0\n",
        "  for trait in traits_bhv:\n",
        "    torch_in = torch.from_numpy(\n",
        "        np.loadtxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\",\n",
        "        delimiter=\",\"))\n",
        "    if flag == 0 :\n",
        "      bhv = torch_in\n",
        "      flag = 1\n",
        "    else:\n",
        "      bhv = torch.cat((bhv, torch_in), dim=1)\n",
        "  #print(bhv.size())\n",
        "  if flag_tot == 0:\n",
        "    big5_tot = b5\n",
        "    bhv_tot = bhv\n",
        "    flag_tot = 1\n",
        "  else:\n",
        "    big5_tot = torch.cat((big5_tot, b5), dim=0)\n",
        "    bhv_tot = torch.cat((bhv_tot, bhv), dim=0)\n",
        "\n",
        "print(big5_tot.size())\n",
        "print(bhv_tot.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6I2JrgLlvw"
      },
      "source": [
        "big5_size = list(big5_tot.size())\n",
        "big5_tot = torch.reshape(big5_tot, (int(big5_size[0]/50), 50, big5_size[1]))\n",
        "#print(big5_tot)\n",
        "print(big5_tot[0].size())\n",
        "bhv_size = list(bhv_tot.size())\n",
        "bhv_tot = torch.reshape(bhv_tot, (int(bhv_size[0]/50), 50, bhv_size[1]))\n",
        "#print(big5_tot)\n",
        "print(bhv_tot[0].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye21RyI_Hxgk"
      },
      "source": [
        "configure the RUNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO0WuHLpnZeG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RUNN(nn.Module):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      big5_in = 768*5,\n",
        "      bhv_in = 768*10\n",
        "      ):\n",
        "        super().__init__()\n",
        "        self.shrink_big5 = nn.Linear(big5_in, 768) # trasformare in sequential \n",
        "        # più relu e batch norm ad ogni livello\n",
        "        self.shrink_bhv = nn.Linear(bhv_in, 768)\n",
        "        self.conv1 = nn.Conv1d(in_channels=50, out_channels=1, kernel_size=3, stride=1)\n",
        "        self.ll = nn.Linear(1534, 1)\n",
        "\n",
        "\n",
        "  def forward(self, big5, bhv):\n",
        "    # aggiungere relu e batch normalization\n",
        "    sb5 = self.shrink_big5(big5) # (50,(768*5) = (50, 768)\n",
        "    sbhv = self.shrink_bhv(bhv) # (50,(768*10) = (50, 768)\n",
        "    print(sb5.size())\n",
        "    print(sbhv.size())\n",
        "    x = torch.cat((sb5, sbhv), dim=1)\n",
        "    x = x.unsqueeze(0)\n",
        "    x = self.conv1(x)\n",
        "    print(\"size dopo conv1\", x.size())\n",
        "    x = self.ll(x)\n",
        "    print(\"size dopo ll\", x.size())\n",
        "    print(\"x\",x)\n",
        "    y = torch.squeeze(x)\n",
        "    print(\"y\", y)\n",
        "    return y\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYhSMEK-Hmg9"
      },
      "source": [
        "train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUyps09eHq4i"
      },
      "source": [
        "model = RUNN()\n",
        "y = model.forward(big5_tot[0].float(), bhv_tot[0].float())\n",
        "y_pred = torch.sigmoid(y)\n",
        "y_pred_tag = torch.round(y_pred)\n",
        "print(y_pred, y_pred_tag)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}