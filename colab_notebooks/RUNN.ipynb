{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RUNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rBZVS9GpnDu"
      },
      "source": [
        "# Relaiable Users Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNxjqFRFmGVg"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezCdYws_mUAW"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mf0xZ1szvb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CYOt4SUT7I"
      },
      "source": [
        "# !ls \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJuRGQ7Mubmj"
      },
      "source": [
        "from numpy.random import seed\n",
        "from numpy.random import randint\n",
        "import torch\n",
        "import numpy as np\n",
        "seed(1)\n",
        "how_many_users = 5\n",
        "values = randint(0, 2, how_many_users)\n",
        "labels = torch.from_numpy(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqtuupvowSxs"
      },
      "source": [
        "pRoot = \"drive/MyDrive/Colab Notebooks/\"\n",
        "pData = pRoot + \"dataset/\"\n",
        "pModels = pRoot + \"models/\"\n",
        "pTweet = pData + \"tweet/\"\n",
        "users_id = []\n",
        "fin = open(pData + \"users_fake_news.txt\", \"r\")\n",
        "for line in fin.readlines():\n",
        "    users_id.append(line.rstrip(\"\\n\"))\n",
        "users_id = users_id[1:11]\n",
        "#print(users_id)\n",
        "print(len(users_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbIfwbuJUz7"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
        "    'distilbert-base-multilingual-cased',\n",
        "    do_lower_case=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ZwcerzcrFr"
      },
      "source": [
        "def preprocess_sentences(input_ids, attention_masks, sentences):\n",
        "  for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,\n",
        "        add_special_tokens = True,\n",
        "        max_length = max_len,\n",
        "        # pad_to_max_length = True,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geCE30CVSdMb"
      },
      "source": [
        "def load_model(modelname):\n",
        "  loaded_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    pModels+modelname, output_hidden_states = True)\n",
        "  return loaded_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MCO6sXoFkOs"
      },
      "source": [
        "Read the first 100 tweets of each user and transform them into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwdheGgZFjvG"
      },
      "source": [
        "import pandas as pd\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "import gc\n",
        "\n",
        "# traits_big5 = ['O','C','E','A','N']\n",
        "# traits_bhv = ['SD', 'ST', 'HE', 'AC', 'PO', 'SE', 'CO', 'TR', 'BE', 'UN']\n",
        "'''\n",
        "trait = \"UN\"\n",
        "max_len = 256 # the closest power of two exceeding max len found\n",
        "model = load_model(\"distil_\"+trait)\n",
        "\n",
        "for user in users_id:   \n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  df = pd.read_csv(pTweet + str(user) + \".csv\")\n",
        "  # print(df.head())\n",
        "  df = df[:50]\n",
        "  df['text']= df['text'].astype('str')\n",
        "  sentences  = df.text.values\n",
        "  input_ids, attention_masks = preprocess_sentences(\n",
        "      input_ids, attention_masks, sentences)\n",
        "  input_ids = input_ids.to(device)\n",
        "  attention_masks = attention_masks.to(device)\n",
        "  pt_output = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "  token_embeddings = torch.stack(pt_output.hidden_states, dim=0)\n",
        "  # print(token_embeddings.size())\n",
        "  last_layer = token_embeddings[-1]\n",
        "  last_layer = last_layer.permute(1,0,2) \n",
        "  # print(last_layer[0].size())\n",
        "  result = last_layer[0].cpu().detach().numpy()\n",
        "  res = np.asarray(result)\n",
        "  np.savetxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\", res, delimiter=\",\", fmt='%5.5f')\n",
        "  del input_ids\n",
        "  del attention_masks\n",
        "  del pt_output\n",
        "  del df\n",
        "  del last_layer\n",
        "  del result\n",
        "  del res\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "print(\"done\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWtDsHkqHh5d"
      },
      "source": [
        "Prepare data into input tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_k3bQzp5Ofk"
      },
      "source": [
        "traits_big5 = ['O','C','E','A','N']\n",
        "traits_bhv = ['SD', 'ST', 'HE', 'AC', 'PO', 'SE', 'CO', 'TR', 'BE', 'UN']\n",
        "flag_tot = 0\n",
        "for user in users_id[:how_many_users]:\n",
        "  flag = 0\n",
        "  for trait in traits_big5:\n",
        "    torch_in = torch.from_numpy(\n",
        "        np.loadtxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\",\n",
        "        delimiter=\",\"))\n",
        "    if flag == 0 :\n",
        "      b5 = torch_in\n",
        "      flag = 1\n",
        "    else:\n",
        "      b5 = torch.cat((b5, torch_in), dim=1)\n",
        "  #print(b5.size())\n",
        "  flag = 0\n",
        "  for trait in traits_bhv:\n",
        "    torch_in = torch.from_numpy(\n",
        "        np.loadtxt(pData+\"user_tensor/\"+str(user)+\"_\"+trait+\".csv\",\n",
        "        delimiter=\",\"))\n",
        "    if flag == 0 :\n",
        "      bhv = torch_in\n",
        "      flag = 1\n",
        "    else:\n",
        "      bhv = torch.cat((bhv, torch_in), dim=1)\n",
        "  #print(bhv.size())\n",
        "  if flag_tot == 0:\n",
        "    big5_tot = b5\n",
        "    bhv_tot = bhv\n",
        "    flag_tot = 1\n",
        "  else:\n",
        "    big5_tot = torch.cat((big5_tot, b5), dim=0)\n",
        "    bhv_tot = torch.cat((bhv_tot, bhv), dim=0)\n",
        "\n",
        "# print(big5_tot.size())\n",
        "# print(bhv_tot.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6I2JrgLlvw"
      },
      "source": [
        "big5_size = list(big5_tot.size())\n",
        "big5_tot = torch.reshape(big5_tot, (int(big5_size[0]/50), 50, big5_size[1]))\n",
        "# print(big5_tot)\n",
        "# print(big5_tot[0].size())\n",
        "bhv_size = list(bhv_tot.size())\n",
        "bhv_tot = torch.reshape(bhv_tot, (int(bhv_size[0]/50), 50, bhv_size[1]))\n",
        "# print(big5_tot)\n",
        "# print(bhv_tot[0].size())\n",
        "# print(big5_tot.size(), bhv_tot.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye21RyI_Hxgk"
      },
      "source": [
        "configure the RUNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO0WuHLpnZeG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RUNN(nn.Module):\n",
        "\n",
        "  def __init__(self, big5_in = 768*5, bhv_in = 768*10):\n",
        "        super().__init__()\n",
        "        # self.shrink_big5 = nn.Linear(big5_in, 768) \n",
        "        self.shrink_big5 = nn.Sequential(\n",
        "            nn.Linear(big5_in, 768), nn.LeakyReLU())\n",
        "        # self.shrink_bhv = nn.Linear(bhv_in, 768)\n",
        "        self.shrink_bhv = nn.Sequential(\n",
        "            nn.Linear(bhv_in, 768), nn.LeakyReLU())       \n",
        "        self.conv1 = nn.Conv1d(\n",
        "            in_channels=50, out_channels=1, kernel_size=3, stride=1)     \n",
        "        self.ll = nn.Linear(1534, 1)\n",
        "\n",
        "\n",
        "  def forward(self, big5, bhv):\n",
        "    sb5 = self.shrink_big5(big5) # (50,(768*5) = (50, 768)\n",
        "    sbhv = self.shrink_bhv(bhv) # (50,(768*10) = (50, 768)\n",
        "    # print(sb5.size())\n",
        "    # print(sbhv.size())\n",
        "    x = torch.cat((sb5, sbhv), dim=2)\n",
        "    # print(x.size())\n",
        "    #x = x.unsqueeze(0)\n",
        "    x = self.conv1(x)\n",
        "    x = self.ll(x)\n",
        "    y = torch.squeeze(x)\n",
        "    return y\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYhSMEK-Hmg9"
      },
      "source": [
        "train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3BOOaZAsVqI",
        "cellView": "code"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(big5_tot.float(), bhv_tot.float(), labels)  # .float() anche le labels?\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1fu3E2FspJN"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup \n",
        "\n",
        "model = RUNN()\n",
        "model.cuda() \n",
        "epochs = 3\n",
        "batch_size = 10\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler = SequentialSampler(val_dataset),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(train_dataloader)*epochs\n",
        ") \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J9HZMHVm1AP"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE4lxG2tZM_B"
      },
      "source": [
        "# y = model.forward(big5_tot[0].float(), bhv_tot[0].float())\n",
        "# y_pred = torch.sigmoid(y)\n",
        "# y_pred_tag = torch.round(y_pred)\n",
        "# print(y_pred, y_pred_tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUyps09eHq4i"
      },
      "source": [
        "import random\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "seed_val = 1\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    total_eval_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 5 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(step, len(train_dataloader), elapsed)\n",
        "\n",
        "        b_big5 = batch[0].to(device)\n",
        "        b_bhv = batch[1].to(device)\n",
        "        b_labels = batch[2].float().to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_big5, b_bhv)\n",
        "        y_pred = torch.sigmoid(outputs)\n",
        "        y_pred_tag = torch.round(y_pred)\n",
        "        loss = loss_fn(y_pred, b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "        loss.type(torch.FloatTensor).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(\"  Average training loss: {0:.8f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, \n",
        "    # measure our performance on our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_micro = [] \n",
        "    eval_macro = [] \n",
        "    eval_acc = 0.0\n",
        "    nb_eval_steps = 0.0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        b_big5 = batch[0].to(device)\n",
        "        b_bhv = batch[1].to(device)\n",
        "        b_labels = batch[2].float().to(device)\n",
        "        with torch.no_grad(): \n",
        "            outputs = model(b_big5, b_bhv)\n",
        "        \n",
        "        \n",
        "        # Accumulate the validation loss.       \n",
        "        y_pred = torch.sigmoid(outputs)\n",
        "        y_pred_tag = torch.round(y_pred)\n",
        "        y_pred_tag = torch.reshape(y_pred_tag, (-1,))\n",
        "        loss = loss_fn(y_pred_tag, b_labels)\n",
        "        total_eval_loss += loss\n",
        "        pred_flat = y_pred_tag.detach().cpu().numpy().flatten()\n",
        "        labels_flat = b_labels.to('cpu').numpy().flatten()\n",
        "        tmp_eval_micro = precision_recall_fscore_support(\n",
        "            labels_flat, pred_flat, average='micro')\n",
        "        tmp_eval_macro = precision_recall_fscore_support(\n",
        "            labels_flat, pred_flat, average='macro')\n",
        "        tmp_accuracy = accuracy_score(\n",
        "            labels_flat, pred_flat\n",
        "        )\n",
        "        # print(tmp_eval_micro)\n",
        "        eval_micro.append(tmp_eval_micro) # += np.asarray(tmp_eval_micro)\n",
        "        eval_macro.append(tmp_eval_macro) #+= np.asarray(tmp_eval_macro)\n",
        "        eval_acc += tmp_accuracy\n",
        "        nb_eval_steps += 1\n",
        "    print(F'\\n\\tValidation micro: {eval_micro}')\n",
        "    print(F'\\n\\tValidation macro: {eval_macro}')\n",
        "    print(F'\\n\\tValidation accuracy: {eval_acc/nb_eval_steps}')\n",
        "    avg_eval_loss = total_eval_loss / len(validation_dataloader)\n",
        "    print(\"  Average validation loss: {0:.8f}\".format(avg_eval_loss))  \n",
        "   \n",
        "torch.save(model.state_dict(), \"RUNN_model_state_dict\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}