{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_fold_FNSC.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPxjJdeUdocSEfzzpnEfCAQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6rBZVS9GpnDu"},"source":["# Fake News Spreader Classifier combined with Random Forest"]},{"cell_type":"code","metadata":{"id":"uNxjqFRFmGVg"},"source":["import torch\n","\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezCdYws_mUAW"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7mf0xZ1szvb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7CYOt4SUT7I"},"source":["!ls \"/content/drive/MyDrive/Colab Notebooks\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJuRGQ7Mubmj"},"source":["from numpy.random import seed\n","from numpy.random import randint\n","import torch\n","import pandas as pd\n","import numpy as np\n","seed(1)\n","dlab = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/user_label_clean.csv\")\n","#dlab = dlab[:50]\n","values = np.asarray(dlab['label'])\n","labels = torch.from_numpy(values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqtuupvowSxs"},"source":["pRoot = \"drive/MyDrive/Colab Notebooks/\"\n","pData = pRoot + \"dataset/\"\n","pModels = pRoot + \"models/\"\n","pTweet = pData + \"tweet_drive/\"\n","users_id = dlab['user_id']\n","# print(users_id)\n","print(len(users_id))\n","print(dlab.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGbIfwbuJUz7"},"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(\n","    'bert-base-multilingual-cased',\n","    do_lower_case=False,\n","    output_hidden_states = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7ZwcerzcrFr"},"source":["def preprocess_sentences(input_ids, attention_masks, sentences, max_len):\n","  for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","        sent,\n","        add_special_tokens = True,\n","        max_length = max_len,\n","        pad_to_max_length = True,\n","        #padding = 'max_length',\n","        return_attention_mask = True,\n","        return_tensors = 'pt'\n","    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  return input_ids, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geCE30CVSdMb"},"source":["from transformers import BertModel\n","bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n","bert.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-MCO6sXoFkOs"},"source":["Read the first n tweets of each user and transform them into tensors"]},{"cell_type":"code","metadata":{"id":"dwdheGgZFjvG"},"source":["import pandas as pd\n","max_len = 128 # the closest power of two exceeding max len found\n","count = 1\n","#users_id = users_id[100:500]\n","user_no_tweet = []\n","'''\n","for user in users_id:#[416:]:\n","  total = []\n","  print(str(count) + \"/\" + str(len(users_id)))\n","  count = count + 1 \n","\n","  df = pd.read_csv(pTweet + str(user) + \".csv\")\n","  # print(df.head())\n","  start = 0\n","  print(df.shape[0])\n","  while start < df.shape[0]:\n","    input_ids = []\n","    attention_masks = []\n","    dfc = df[start:start+32]\n","    start = start+32\n","    dfc['text']= dfc['text'].astype('str')\n","    sentences  = dfc.text.values\n","    #print(sentences)\n","\n","    input_ids, attention_masks = preprocess_sentences(\n","        input_ids, attention_masks, sentences, max_len)\n","\n","    #print(input_ids)\n","    input_ids = input_ids.to(device)\n","    outputs = bert(input_ids)\n","    #print(pt_output)\n","    #print(outputs.last_hidden_state.shape)\n","    last_layer = outputs.last_hidden_state.permute(1,0,2) \n","    #print(last_layer[0].size()) #cls\n","    result = last_layer[0].cpu().detach().numpy()\n","    res = np.asarray(result)\n","    #print(res)\n","    #print(res.shape)\n","    res = np.amax(res, axis=0)\n","    #print(res)\n","    #print(res.shape)\n","    total.append(res)\n","#print(len(total))\n","  total = np.asarray(total)\n","  total = np.amax(total, axis=0)\n","  np.savetxt(pData+\"user_tensor/\"+str(user)+\"_max_cls.csv\", total, delimiter=\",\", fmt='%5.5f')\n","#print(total.shape)\n","print(\"done\")\n","'''\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDNYaONoY-iu"},"source":["'''count = 0\n","for user in users_id:\n","  df = pd.read_csv(pData+\"user_tensor/\"+str(user)+\"_max_cls.csv\")\n","  print(str(count))\n","  count += 1'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWtDsHkqHh5d"},"source":["Prepare data into input tensors"]},{"cell_type":"code","metadata":{"id":"aFASwUSIP_zo"},"source":["# debug\n","'''\n","slicedf = dlab[:10]\n","values = np.asarray(slicedf['label'])\n","labels = torch.from_numpy(values)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_k3bQzp5Ofk"},"source":["flag = 0\n","for user in users_id: \n","  torch_in = torch.from_numpy(\n","  np.loadtxt(pData+\"user_tensor/\"+str(user)+\"_max_cls.csv\",delimiter=\",\"))\n","  torch_in = torch.reshape(torch_in, (torch_in.size()[0], 1))\n","  #print(torch_in.size())\n","  if flag == 0 :\n","    max_cls = torch_in\n","    flag = 1\n","  else:\n","    max_cls = torch.cat((max_cls, torch_in), dim=1)\n","\n","print(max_cls.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvgIqKwmVyuc"},"source":["max_cls = max_cls.permute(1,0)\n","print(max_cls.size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ye21RyI_Hxgk"},"source":["configure the architecture"]},{"cell_type":"code","metadata":{"id":"DO0WuHLpnZeG"},"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class FNSC(nn.Module):\n","\n","  def __init__(self):\n","        super().__init__()\n","        self.shrink_cls = nn.Sequential(\n","            nn.LeakyReLU(),nn.Linear(768, 1))\n","\n","\n","  def forward(self, cls):\n","    #print(cls.size())\n","    scls = self.shrink_cls(cls)\n","    y = torch.squeeze(scls)\n","    return y\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYhSMEK-Hmg9"},"source":["train and test the model"]},{"cell_type":"code","metadata":{"id":"3J9HZMHVm1AP"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yE4lxG2tZM_B"},"source":["model = FNSC()\n","model.cuda()\n","# y = model.forward(max_cls.float().to(device), user_info)\n","# y_pred = torch.sigmoid(y)\n","# y_pred_tag = torch.round(y_pred)\n","# print(y_pred, y_pred_tag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlBK8gGGt0Nz"},"source":["import random\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","\n","seed_val = 1 \n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","training_stats = []\n","total_t0 = time.time()\n","\n","def model_fit(epochs, model,loss_fn, optimizer, scheduler, train_dataloader):\n","  for epoch_i in range(0, epochs):\n","      print('Training...')\n","      t0 = time.time()\n","      total_train_loss = 0\n","      total_eval_loss = 0\n","      model.train()\n","      for step, batch in enumerate(train_dataloader):\n","          if step % 40 == 0 and not step == 0:\n","              elapsed = format_time(time.time() - t0)\n","              #print('Batch {:>5,} of {:>5,} .Elapsed: {:}.'.format(\n","                  #step, len(train_dataloader), elapsed))\n","          b_cls = batch[0].to(device)\n","          b_labels = batch[1].to(device)\n","          model.zero_grad()        \n","          outputs = model(b_cls)\n","          #print(outputs.loss)\n","          y_pred = torch.sigmoid(outputs)\n","          print(y_pred, b_labels)\n","          loss = loss_fn(y_pred, b_labels)\n","          total_train_loss += loss.item()\n","          loss.type(torch.FloatTensor).backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","          optimizer.step()\n","          scheduler.step()\n","\n","      avg_train_loss = total_train_loss / len(train_dataloader)            \n","      training_time = format_time(time.time() - t0)\n","\n","      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","      print(\"  Training epoch took: {:}\".format(training_time))\n","  return model\n","\n","def model_test(model, validation_dataloader):     \n","    print(\"Model Test...\")\n","    t0 = time.time()\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0.0\n","    eval_micro = [] \n","    eval_macro = []\n","    eval_acc = 0.0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        b_cls = batch[0].to(device)\n","        b_labels = batch[1].to(device)\n","\n","        with torch.no_grad():        \n","            outputs = model(b_cls)\n","\n","                       \n","        y_pred = torch.sigmoid(outputs)\n","        y_pred_tag = torch.round(y_pred)\n","        y_pred_tag = torch.reshape(y_pred_tag, (-1,))\n","        loss = loss_fn(y_pred_tag, b_labels)\n","        total_eval_loss += loss\n","        pred_flat = y_pred_tag.detach().cpu().numpy().flatten()\n","        labels_flat = b_labels.to('cpu').numpy().flatten()\n","        tmp_eval_micro = precision_recall_fscore_support(\n","            labels_flat, pred_flat, average='micro')\n","        tmp_eval_macro = precision_recall_fscore_support(\n","            labels_flat, pred_flat, average='macro')\n","        tmp_accuracy = accuracy_score(\n","            labels_flat, pred_flat\n","        )\n","        # print(tmp_eval_micro)\n","        eval_micro.append(tmp_eval_micro) # += np.asarray(tmp_eval_micro)\n","        eval_macro.append(tmp_eval_macro) #+= np.asarray(tmp_eval_macro)\n","        eval_acc += tmp_accuracy\n","        nb_eval_steps += 1\n","    print(F'\\n\\tValidation micro: {eval_micro}')\n","    print(F'\\n\\tValidation macro: {eval_macro}')\n","    print(F'\\n\\tValidation accuracy: {eval_acc/nb_eval_steps}')\n","    avg_eval_loss = total_eval_loss / len(validation_dataloader)\n","    print(\"  Average validation loss: {0:.8f}\".format(avg_eval_loss))        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.5f}\".format(avg_val_accuracy))\n","\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","\n","    return eval_micro, eval_macro, eval_acc/nb_eval_steps\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amgrtQQ8hKFK"},"source":["from torch.utils.data import TensorDataset\n","from sklearn.model_selection import KFold\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import get_linear_schedule_with_warmup \n","\n","epochs = 1\n","batch_size = 32\n","optimizer = torch.optim.Adam(model.parameters(), lr = 2e-5, eps = 1e-8)\n","n_splits = 10\n","loss_fn = nn.BCELoss()\n","kf = KFold(n_splits=n_splits)\n","eval_micro = []\n","eval_macro = []\n","eval_acc = 0.0\n","for train_index, test_index in kf.split(max_cls):\n","  print(\"Run\")\n","  max_cls_train, max_cls_test = max_cls[train_index], max_cls[test_index]\n","  labels_train, labels_test = labels[train_index], labels[test_index]\n","\n","  train_ds = TensorDataset(max_cls_train.float(),\n","                           labels_train.float())\n","  train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","  total_steps = len(train_dl) * epochs\n","  scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps = 0,\n","    num_training_steps = total_steps\n","  )\n","  model_fitted = model_fit(epochs, model, loss_fn, optimizer, scheduler, train_dl)\n","  validation_ds = TensorDataset(max_cls_test.float(),\n","                          labels_test.float())\n","  validation_dl = DataLoader(validation_ds, batch_size=batch_size, shuffle=True)\n","  emi, ema, eacc =  model_test(model_fitted, validation_dl)\n","  eval_micro.append(emi)\n","  eval_macro.append(ema)\n","  eval_acc += eacc\n","eval_acc = eval_acc/n_splits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrUGMPA5GR-5"},"source":["print(eval_micro)\n","print(eval_macro)\n","print(eval_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKPBiZ7516Zl"},"source":["print(len(eval_macro))\n","print(len(eval_macro[0]))\n","print(len(eval_macro[0][0]))\n","count = 0\n","sum_metric = 0.0\n","for elem in eval_macro:\n","  #print(elem[0])\n","  for prec in elem:\n","    #print(prec[0])\n","    sum_metric += float(prec[0])\n","    count +=1\n","\n","print(count)\n","print(sum_metric)\n","print(str(sum_metric/count))"],"execution_count":null,"outputs":[]}]}